"""
Data models for the V2 multi-agent tool generation pipeline.

This module defines all the data structures used by the 7 specialized agents:
- Intake Agent
- Search Agent
- Planner Agent
- Implementer Agent
- Test Agent
- Reviewer Agent
- Summarizer Agent
"""

from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any


# ===== Intake Agent Models =====

class ToolDefinition(BaseModel):
    """
    Synthesized tool specification from user requirements.
    Generated by Intake Agent.
    """
    name: str = Field(..., description="Snake_case function name")
    signature: str = Field(..., description="Full Python function signature with type hints")
    docstring: str = Field(..., description="Comprehensive docstring with parameters, returns, examples")
    contracts: List[str] = Field(default_factory=list, description="Pre/post conditions and validation rules")


class IntakeOutput(BaseModel):
    """
    Output from Intake Agent validation and normalization.
    """
    tool_definition: Optional[ToolDefinition] = Field(None, description="Synthesized tool definition (None if invalid)")
    open_questions: List[str] = Field(default_factory=list, description="Questions for Search Agent to investigate")
    validation_status: str = Field(..., description="Status: 'valid', 'needs_clarification', or 'invalid'")
    error: Optional[str] = Field(None, description="Error message if validation_status is 'invalid'")


# ===== Search Agent Models =====

class ParameterSpec(BaseModel):
    """
    Specification for a single function parameter.
    """
    name: str
    type: str
    description: str
    default: Optional[Any] = None
    required: bool = True


class OutputSpec(BaseModel):
    """
    Specification for function output.
    """
    type: str
    description: str
    units: Optional[str] = None


class CodeExample(BaseModel):
    """
    Code example from documentation or tests.
    """
    code: str
    description: str
    source: str = Field(..., description="Source file path or URL")


class ApiFunction(BaseModel):
    """
    API function reference from library documentation.
    """
    function_name: str = Field(..., description="Fully qualified name (e.g., 'rdkit.Chem.Descriptors.MolWt')")
    description: str
    input_schema: List[ParameterSpec]
    output_schema: OutputSpec
    examples: List[CodeExample] = Field(default_factory=list)


class QuestionAnswer(BaseModel):
    """
    Answer to an open question from Intake Agent.
    """
    question: str = Field(..., description="Original question from Intake Agent")
    type: str = Field(..., description="Type: 'api_discovery', 'method_selection', 'parameter_tuning', 'format_handling', 'error_handling', 'units'")
    answer: str = Field(..., description="Detailed answer extracted from documentation")
    library: Optional[str] = Field(None, description="Relevant library (rdkit, ase, pymatgen, pyscf, orca)")
    code_example: Optional[str] = Field(None, description="Code snippet demonstrating the answer")


class ExplorationReport(BaseModel):
    """
    Consolidated report from Search Agent exploration.
    """
    apis: List[ApiFunction] = Field(default_factory=list, description="Relevant API functions found")
    paths: List[str] = Field(default_factory=list, description="Relevant file paths in repository")
    entry_points: List[str] = Field(default_factory=list, description="Main functions to call")
    examples: List[CodeExample] = Field(default_factory=list, description="Code examples from docs/tests")
    api_refs_file: str = Field(..., description="Path to generated API reference file (.md or .json)")
    question_answers: List[QuestionAnswer] = Field(default_factory=list, description="Answers to open questions from Intake Agent")


# ===== Planner Agent Models =====

class PlanStep(BaseModel):
    """
    Single step in implementation plan.
    """
    step_number: int
    action: str = Field(..., description="Action type: 'parse_input', 'call_api', 'validate', 'format_output', etc.")
    description: str = Field(..., description="Detailed description of what this step does")
    apis_used: List[str] = Field(default_factory=list, description="API functions called in this step")
    error_handling: str = Field(..., description="Error handling strategy for this step")


class ImplementationPlan(BaseModel):
    """
    Extended implementation plan with detailed steps.
    Extends the basic plan structure with V2 enhancements.
    """
    task_id: str
    job_id: str
    requirement_name: str = Field(..., description="Tool name from requirement")
    requirement_description: str = Field(..., description="Tool description")

    # API references
    api_refs: List[str] = Field(default_factory=list, description="List of API function names to use")

    # V2 additions
    steps: List[PlanStep] = Field(default_factory=list, description="Step-by-step execution plan")
    validation_rules: List[str] = Field(default_factory=list, description="Data validation rules to implement")
    expected_artifacts: List[str] = Field(default_factory=list, description="Expected output files/data structures")


# ===== Implementer Agent Models =====

class ImplementationResult(BaseModel):
    """
    Result from Implementer Agent code generation.
    """
    success: bool
    tool_file_path: str = Field(..., description="Path to generated tool file (e.g., 'tools/<job_id>/<task_id>/tool.py')")
    tool_code: str = Field(..., description="Generated Python code")
    error: Optional[str] = Field(None, description="Error message if success is False")


# ===== Test Agent Models =====

class TestResult(BaseModel):
    """
    Result from Test Agent test generation.
    """
    success: bool
    test_file_path: str = Field(..., description="Path to generated test file")
    test_code: str = Field(..., description="Generated test code")
    fixtures_created: List[str] = Field(default_factory=list, description="Paths to created fixture files")
    test_types: List[str] = Field(default_factory=list, description="Types of tests generated: 'unit', 'property', 'golden', 'integration'")
    error: Optional[str] = Field(None, description="Error message if success is False")


class TestFailure(BaseModel):
    """
    Information about a single test failure.
    """
    test_name: str
    error_message: str
    traceback: str


class TestResults(BaseModel):
    """
    Parsed pytest execution results.
    """
    passed: int = 0
    failed: int = 0
    errors: int = 0
    failures: List[TestFailure] = Field(default_factory=list)
    coverage: Optional[float] = None
    duration: Optional[float] = Field(None, description="Total test execution time in seconds")


# ===== Reviewer Agent Models =====

class Issue(BaseModel):
    """
    Code issue identified during review.
    """
    severity: str = Field(..., description="Severity: 'critical', 'major', or 'minor'")
    category: str = Field(..., description="Category: 'style', 'contracts', 'complexity', 'determinism', 'correctness'")
    description: str


class Change(BaseModel):
    """
    Requested change to code or tests.
    """
    type: str = Field(..., description="Change type: 'fix_bug', 'add_validation', 'simplify', 'improve_docs', etc.")
    description: str
    rationale: str


class ReviewInput(BaseModel):
    """
    Input provided to Reviewer Agent.
    """
    tool_code: str
    test_code: str
    test_results: TestResults
    plan: ImplementationPlan
    iteration: int


class ReviewReport(BaseModel):
    """
    Review report from Reviewer Agent.
    """
    approved: bool = Field(..., description="True if tool is ready to deploy, False if re-implementation needed")
    issues: List[Issue] = Field(default_factory=list)
    required_changes: List[Change] = Field(default_factory=list, description="Changes that must be made")
    optional_improvements: List[Change] = Field(default_factory=list, description="Suggestions for improvement")
    summary: str = Field(..., description="Brief summary of review")


# ===== Summarizer Agent Models =====

class IterationData(BaseModel):
    """
    Data from a single iteration to be summarized.
    """
    iteration: int
    logs: List[str] = Field(default_factory=list, description="Log messages from this iteration")
    failures: List[TestFailure] = Field(default_factory=list)
    review_report: ReviewReport
    plan: ImplementationPlan


class IterationSummary(BaseModel):
    """
    Compressed summary of an iteration.
    """
    iteration: int
    what_failed: str = Field(..., description="Concise description of what failed")
    what_changed: str = Field(..., description="Changes made from previous iteration")
    why_changed: str = Field(..., description="Rationale for changes")
    next_focus: str = Field(..., description="What to prioritize in next iteration")
    memory_size: int = Field(..., description="Approximate size of this summary in characters")


# ===== Pipeline-Level Models =====

class PipelineContext(BaseModel):
    """
    Context passed through the entire pipeline.
    """
    task_id: str
    job_id: str
    iteration: int = 1
    max_iterations: int = 3
    iteration_history: List[IterationSummary] = Field(default_factory=list)
